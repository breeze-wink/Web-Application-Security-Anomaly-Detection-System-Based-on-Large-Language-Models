#!/usr/bin/env python3
"""LangChainå®‰å…¨åˆ†ææ¼”ç¤ºè„šæœ¬"""

import asyncio
import os
from datetime import datetime
from app.llm.langchain_provider import LangChainProvider
from app.llm.prompt_templates import SecurityAnalysisPrompts, PromptBuilder
from app.llm.chain_factory import ChainManager
from app.core.models import SecurityEvent, HTTPRequest, DetectionResult, AttackType


def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("=" * 60)
    print("ğŸ”’ LangChainå®‰å…¨åˆ†ææ¼”ç¤º")
    print("=" * 60)


def create_demo_security_events():
    """åˆ›å»ºæ¼”ç¤ºç”¨çš„å®‰å…¨äº‹ä»¶"""
    events = []
    
    # SQLæ³¨å…¥äº‹ä»¶
    sql_request = HTTPRequest(
        url="/admin/login?id=1' OR 1=1--",
        method="POST",
        headers={"User-Agent": "Mozilla/5.0"},
        params={"id": "1' OR 1=1--"},
        body=None,
        source_ip="192.168.1.100",
        timestamp=datetime.now(),
        raw_data="POST /admin/login?id=1' OR 1=1-- HTTP/1.1"
    )
    
    sql_detection = DetectionResult(
        is_attack=True,
        attack_types=[AttackType.SQL_INJECTION],
        confidence=0.95,
        payload="1' OR 1=1--"
    )
    
    sql_event = SecurityEvent(
        event_id="demo_sql_001",
        request=sql_request,
        detection=sql_detection
    )
    events.append(("SQLæ³¨å…¥æ”»å‡»", sql_event))
    
    # XSSæ”»å‡»äº‹ä»¶
    xss_request = HTTPRequest(
        url="/search?q=<script>alert('XSS')</script>",
        method="GET",
        headers={"User-Agent": "Mozilla/5.0"},
        params={"q": "<script>alert('XSS')</script>"},
        body=None,
        source_ip="10.0.0.50",
        timestamp=datetime.now(),
        raw_data="GET /search?q=<script>alert('XSS')</script> HTTP/1.1"
    )
    
    xss_detection = DetectionResult(
        is_attack=True,
        attack_types=[AttackType.XSS],
        confidence=0.88,
        payload="<script>alert('XSS')</script>"
    )
    
    xss_event = SecurityEvent(
        event_id="demo_xss_001",
        request=xss_request,
        detection=xss_detection
    )
    events.append(("XSSæ”»å‡»", xss_event))
    
    return events


def demo_prompt_templates():
    """æ¼”ç¤ºæç¤ºè¯æ¨¡æ¿åŠŸèƒ½"""
    print("\nğŸ“ æç¤ºè¯æ¨¡æ¿æ¼”ç¤º")
    print("-" * 40)
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡æ¿
    templates = SecurityAnalysisPrompts.list_available_templates()
    print(f"å¯ç”¨æ¨¡æ¿: {', '.join(templates)}")
    
    # æ¼”ç¤ºåŸºç¡€å¨èƒåˆ†ææ¨¡æ¿
    print("\nğŸ” åŸºç¡€å¨èƒåˆ†ææ¨¡æ¿:")
    template = SecurityAnalysisPrompts.get_prompt_template("threat_analysis")
    print(f"æ¨¡æ¿å˜é‡: {template.input_variables}")
    
    # æ¼”ç¤ºSQLæ³¨å…¥ä¸“é¡¹æ¨¡æ¿
    print("\nğŸ’‰ SQLæ³¨å…¥ä¸“é¡¹åˆ†ææ¨¡æ¿:")
    sql_template = SecurityAnalysisPrompts.get_prompt_template("sql_injection")
    print(f"æ¨¡æ¿å˜é‡: {sql_template.input_variables}")


def demo_prompt_builder():
    """æ¼”ç¤ºæç¤ºè¯æ„å»ºå™¨"""
    print("\nğŸ”§ æç¤ºè¯æ„å»ºå™¨æ¼”ç¤º")
    print("-" * 40)
    
    builder = PromptBuilder()
    
    # æ¨¡æ‹Ÿäº‹ä»¶æ•°æ®
    event_data = {
        "source_ip": "192.168.1.100",
        "target_url": "/admin/login?id=1' OR 1=1--",
        "http_method": "POST",
        "user_agent": "Mozilla/5.0",
        "detection_time": "2024-01-01 10:00:00",
        "threat_types": "SQLæ³¨å…¥",
        "confidence": "0.95",
        "attack_payload": "1' OR 1=1--",
        "raw_request": "POST /admin/login HTTP/1.1"
    }
    
    # æ„å»ºå¨èƒåˆ†ææç¤ºè¯
    prompt = builder.build_threat_analysis_prompt(event_data)
    print("æ„å»ºçš„æç¤ºè¯ç‰‡æ®µ:")
    print(prompt[:200] + "...")


async def demo_chain_factory():
    """æ¼”ç¤ºé“¾å·¥å‚åŠŸèƒ½"""
    print("\nâ›“ï¸ é“¾å·¥å‚æ¼”ç¤º")
    print("-" * 40)
    
    # æ¨¡æ‹ŸLLMï¼ˆåœ¨çœŸå®ç¯å¢ƒä¸­ä¼šä½¿ç”¨çœŸå®çš„ChatOpenAIï¼‰
    class MockLLM:
        async def arun(self, **kwargs):
            return '{"severity": "HIGH", "attack_intent": "æ¼”ç¤ºæ”»å‡»æ„å›¾", "confidence_score": 0.9}'
    
    mock_llm = MockLLM()
    
    try:
        from app.llm.chain_factory import SecurityAnalysisChainFactory
        factory = SecurityAnalysisChainFactory(mock_llm)
        
        # æ˜¾ç¤ºæ”¯æŒçš„å¨èƒç±»å‹
        threat_types = factory.get_supported_threat_types()
        print(f"æ”¯æŒçš„å¨èƒç±»å‹: {threat_types}")
        
        # åˆ›å»ºåŸºç¡€åˆ†æé“¾
        basic_chain = factory.create_basic_analysis_chain()
        print(f"åŸºç¡€åˆ†æé“¾è¾“å‡ºé”®: {basic_chain.output_key}")
        
        # åˆ›å»ºå¹¶è¡Œåˆ†æé“¾
        parallel_chains = factory.create_parallel_analysis_chain(["sql_injection", "xss"])
        print(f"å¹¶è¡Œåˆ†æé“¾æ•°é‡: {len(parallel_chains)}")
        print(f"å¹¶è¡Œåˆ†æé“¾é”®: {list(parallel_chains.keys())}")
        
        print("âœ… é“¾å·¥å‚åŠŸèƒ½æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ é“¾å·¥å‚æ¼”ç¤ºå¤±è´¥: {e}")


async def demo_security_analysis(use_real_api=False):
    """æ¼”ç¤ºå®‰å…¨åˆ†æåŠŸèƒ½"""
    print("\nğŸ›¡ï¸ å®‰å…¨åˆ†ææ¼”ç¤º")
    print("-" * 40)
    
    if use_real_api:
        # ä½¿ç”¨çœŸå®API
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ éœ€è¦è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
            return
        
        config = {
            "api_key": api_key,
            "model": "gpt-3.5-turbo",
            "temperature": 0.1
        }
        
        print("ğŸŒ ä½¿ç”¨çœŸå®OpenAI API")
    else:
        # ä½¿ç”¨Mockæ¨¡å¼æ¼”ç¤º
        print("ğŸ”„ ä½¿ç”¨Mockæ¨¡å¼æ¼”ç¤º")
        return  # åœ¨Mockæ¨¡å¼ä¸‹è·³è¿‡è¿™ä¸ªæ¼”ç¤º
    
    # åˆ›å»ºæ¼”ç¤ºäº‹ä»¶
    events = create_demo_security_events()
    
    try:
        provider = LangChainProvider(config)
        
        for event_name, event in events:
            print(f"\nğŸ“Š åˆ†æ {event_name}:")
            print(f"   æ¥æºIP: {event.request.source_ip}")
            print(f"   ç›®æ ‡URL: {event.request.url}")
            print(f"   æ”»å‡»è½½è·: {event.detection.payload}")
            
            if use_real_api:
                # æ‰§è¡ŒçœŸå®åˆ†æ
                result = await provider.analyze_security_event(event)
                
                print(f"   åˆ†æç»“æœ:")
                print(f"     å¨èƒç­‰çº§: {result.severity.value}")
                print(f"     æ”»å‡»æ„å›¾: {result.attack_intent[:100]}...")
                print(f"     ç½®ä¿¡åº¦: {result.confidence:.2f}")
                print(f"     å»ºè®®æ•°é‡: {len(result.recommendations)}")
            else:
                print("   [Mockæ¨¡å¼ - è·³è¿‡çœŸå®åˆ†æ]")
            
    except Exception as e:
        print(f"âŒ å®‰å…¨åˆ†ææ¼”ç¤ºå¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # æ¼”ç¤ºå„ä¸ªç»„ä»¶
    demo_prompt_templates()
    demo_prompt_builder()
    await demo_chain_factory()
    
    # è¯¢é—®æ˜¯å¦ä½¿ç”¨çœŸå®API
    print("\n" + "=" * 60)
    choice = input("æ˜¯å¦ä½¿ç”¨çœŸå®OpenAI APIè¿›è¡Œæ¼”ç¤º? (éœ€è¦API key) [y/N]: ").lower().strip()
    use_real_api = choice in ['y', 'yes']
    
    await demo_security_analysis(use_real_api)
    
    print("\n" + "=" * 60)
    print("âœ… LangChainå®‰å…¨åˆ†ææ¼”ç¤ºå®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main()) 